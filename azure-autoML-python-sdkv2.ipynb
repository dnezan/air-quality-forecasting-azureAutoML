{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a994cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import automl\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be9b194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "\n",
    "\n",
    "credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4724f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .\\config.json\n"
     ]
    }
   ],
   "source": [
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"98dcfdf0-c14b-4a76-9961-31fff2d85560\"\n",
    "    resource_group = \"sales-forecast\"\n",
    "    workspace = \"sales-forecast-ws1\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c77184d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = ml_client.workspaces.get(name=ml_client.workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bbcd64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "output[\"Workspace\"] = ml_client.workspace_name\n",
    "output[\"Subscription ID\"] = ml_client.connections._subscription_id\n",
    "output[\"Resource Group\"] = workspace.resource_group\n",
    "output[\"Location\"] = workspace.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e2e670c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>sales-forecast-ws1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>98dcfdf0-c14b-4a76-9961-31fff2d85560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>sales-forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>eastus2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     \n",
       "Workspace                          sales-forecast-ws1\n",
       "Subscription ID  98dcfdf0-c14b-4a76-9961-31fff2d85560\n",
       "Resource Group                         sales-forecast\n",
       "Location                                      eastus2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "outputDf = pd.DataFrame(data=output, index=[\"\"])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74df743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "\n",
    "def create_ml_table(csv_file, output, delimiter=\",\", encoding=\"ascii\"):\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    fname = os.path.split(csv_file)[-1]\n",
    "    mltable = {\n",
    "        \"paths\": [{\"file\": f\"./{fname}\"}],\n",
    "        \"transformations\": [\n",
    "            {\"read_delimited\": {\"delimiter\": delimiter, \"encoding\": encoding}}\n",
    "        ],\n",
    "    }\n",
    "    with open(os.path.join(output, \"MLTable\"), \"w\") as f:\n",
    "        f.write(yaml.dump(mltable))\n",
    "    shutil.copy(csv_file, os.path.join(output, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4f64440",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ml_table(\"train.csv\", \"./data/training-mltable-folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f6953ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training MLTable defined locally, with local data to be uploaded\n",
    "my_training_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, path=\"./data/training-mltable-folder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "691ae8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cluster_name = \"sales-forecast-compute2\"\n",
    "compute = ml_client.compute.get(cluster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcd52a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name=\"sales_forecast_exp1\"\n",
    "\n",
    "forecasting_job = automl.forecasting(\n",
    "    compute=cluster_name,\n",
    "    experiment_name=exp_name,\n",
    "    training_data=my_training_data_input,\n",
    "    target_column_name=\"sales\",\n",
    "    primary_metric=\"NormalizedRootMeanSquaredError\",\n",
    "    n_cross_validations=\"auto\",\n",
    "    enable_model_explainability=True,\n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "forecasting_job.set_limits(\n",
    "    timeout_minutes=90,\n",
    "    trial_timeout_minutes=90,\n",
    "    enable_early_termination=True,\n",
    "    max_concurrent_trials=1,\n",
    ")\n",
    "\n",
    "# Specialized properties for Time Series Forecasting training\n",
    "forecasting_job.set_forecast_settings(\n",
    "    time_column_name=\"date\",\n",
    "    forecast_horizon=14,\n",
    "    frequency=\"D\",\n",
    "    target_lags=\"auto\",\n",
    "    country_or_region_for_holidays=\"US\",\n",
    ")\n",
    "\n",
    "# Training properties are optional\n",
    "forecasting_job.set_training(blocked_training_algorithms=[\"ExtremeRandomTrees\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c39bebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job: compute: azureml:sales-forecast-compute2\n",
      "creation_context:\n",
      "  created_at: '2023-03-30T10:02:36.565217+00:00'\n",
      "  created_by: Sreekanthan\n",
      "  created_by_type: User\n",
      "display_name: nice_leg_tyswsh7g97\n",
      "experiment_name: sales_forecast_exp1\n",
      "forecasting:\n",
      "  country_or_region_for_holidays: US\n",
      "  feature_lags: none\n",
      "  forecast_horizon: 14\n",
      "  frequency: D\n",
      "  seasonality: auto\n",
      "  short_series_handling_config: auto\n",
      "  target_aggregate_function: none\n",
      "  target_lags: auto\n",
      "  time_column_name: date\n",
      "  use_stl: none\n",
      "id: azureml:/subscriptions/98dcfdf0-c14b-4a76-9961-31fff2d85560/resourceGroups/sales-forecast/providers/Microsoft.MachineLearningServices/workspaces/sales-forecast-ws1/jobs/nice_leg_tyswsh7g97\n",
      "limits:\n",
      "  enable_early_termination: true\n",
      "  max_concurrent_trials: 1\n",
      "  max_cores_per_trial: -1\n",
      "  max_trials: 1000\n",
      "  timeout_minutes: 90\n",
      "  trial_timeout_minutes: 90\n",
      "log_verbosity: info\n",
      "n_cross_validations: auto\n",
      "name: nice_leg_tyswsh7g97\n",
      "outputs: {}\n",
      "primary_metric: normalized_root_mean_squared_error\n",
      "properties:\n",
      "  azureml.git.dirty: 'True'\n",
      "  mlflow.source.git.branch: master\n",
      "  mlflow.source.git.commit: 833eaba9cb007d7ab5ee85adceea0f8dc29f5eae\n",
      "  mlflow.source.git.repoURL: https://github.com/dnezan/azure-autoML-python.git\n",
      "queue_settings:\n",
      "  job_tier: Standard\n",
      "resources:\n",
      "  instance_count: 1\n",
      "  shm_size: 2g\n",
      "services:\n",
      "  Studio:\n",
      "    endpoint: https://ml.azure.com/runs/nice_leg_tyswsh7g97?wsid=/subscriptions/98dcfdf0-c14b-4a76-9961-31fff2d85560/resourcegroups/sales-forecast/workspaces/sales-forecast-ws1&tid=aef6baf5-6231-4690-9308-23d674d56b05\n",
      "    job_service_type: Studio\n",
      "  Tracking:\n",
      "    endpoint: azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/98dcfdf0-c14b-4a76-9961-31fff2d85560/resourceGroups/sales-forecast/providers/Microsoft.MachineLearningServices/workspaces/sales-forecast-ws1?\n",
      "    job_service_type: Tracking\n",
      "status: NotStarted\n",
      "tags: {}\n",
      "target_column_name: sales\n",
      "task: forecasting\n",
      "training:\n",
      "  blocked_training_algorithms:\n",
      "  - extreme_random_trees\n",
      "  enable_dnn_training: false\n",
      "  enable_model_explainability: true\n",
      "  enable_onnx_compatible_models: false\n",
      "  enable_stack_ensemble: false\n",
      "  enable_vote_ensemble: true\n",
      "  ensemble_model_download_timeout_minutes: 5\n",
      "training_data:\n",
      "  path: azureml://datastores/workspaceblobstore/paths/LocalUpload/47e045c56ae46181ddb7106d4d7bf204/training-mltable-folder\n",
      "  type: mltable\n",
      "type: automl\n",
      "validation_data:\n",
      "  type: mltable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(forecasting_job)  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40e59ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: nice_leg_tyswsh7g97\n",
      "Web View: https://ml.azure.com/runs/nice_leg_tyswsh7g97?wsid=/subscriptions/98dcfdf0-c14b-4a76-9961-31fff2d85560/resourcegroups/sales-forecast/workspaces/sales-forecast-ws1\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: nice_leg_tyswsh7g97\n",
      "Web View: https://ml.azure.com/runs/nice_leg_tyswsh7g97?wsid=/subscriptions/98dcfdf0-c14b-4a76-9961-31fff2d85560/resourcegroups/sales-forecast/workspaces/sales-forecast-ws1\n"
     ]
    },
    {
     "ename": "JobException",
     "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"There is not enough memory on the machine to do the operation. The amount of available memory is 1257250816 out of 8337788928 total memory. To fit the model at least 3233686480 more memory is required. Please try running the experiment on a VM with higher memory.\\nIf your data have multiple time series, you can also consider using many model solution to workaround the memory issue, please refer to https://aka.ms/manymodel for details.\",\n        \"message_format\": \"There is not enough memory on the machine to do the operation. The amount of available memory is {avail_mem} out of {total_mem} total memory. To fit the model at least {min_mem} more memory is required. Please try running the experiment on a VM with higher memory.\\nIf your data have multiple time series, you can also consider using many model solution to workaround the memory issue, please refer to https://aka.ms/manymodel for details.\",\n        \"message_parameters\": {\n            \"avail_mem\": \"1257250816\",\n            \"total_mem\": \"8337788928\",\n            \"min_mem\": \"3233686480\"\n        },\n        \"details_uri\": \"https://aka.ms/azurevmsizes\",\n        \"details\": [],\n        \"inner_error\": {\n            \"code\": \"ResourceExhausted\",\n            \"inner_error\": {\n                \"code\": \"Memory\"\n            }\n        }\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n} ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJobException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27728\\2912176339.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mml_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturned_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\core\\tracing\\decorator.py\u001b[0m in \u001b[0;36mwrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mspan_impl_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracing_implementation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspan_impl_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;31m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mlog_activity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_name\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mPipelineChildJobError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjob_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         self._stream_logs_until_completion(\n\u001b[0m\u001b[0;32m    646\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_runs_operations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datastore_operations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequests_pipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_requests_pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_ops_helper.py\u001b[0m in \u001b[0;36mstream_logs_until_completion\u001b[1;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[0;32m    293\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 raise JobException(\n\u001b[0m\u001b[0;32m    296\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Exception : \\n {} \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m                     \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mErrorTarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJOB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"There is not enough memory on the machine to do the operation. The amount of available memory is 1257250816 out of 8337788928 total memory. To fit the model at least 3233686480 more memory is required. Please try running the experiment on a VM with higher memory.\\nIf your data have multiple time series, you can also consider using many model solution to workaround the memory issue, please refer to https://aka.ms/manymodel for details.\",\n        \"message_format\": \"There is not enough memory on the machine to do the operation. The amount of available memory is {avail_mem} out of {total_mem} total memory. To fit the model at least {min_mem} more memory is required. Please try running the experiment on a VM with higher memory.\\nIf your data have multiple time series, you can also consider using many model solution to workaround the memory issue, please refer to https://aka.ms/manymodel for details.\",\n        \"message_parameters\": {\n            \"avail_mem\": \"1257250816\",\n            \"total_mem\": \"8337788928\",\n            \"min_mem\": \"3233686480\"\n        },\n        \"details_uri\": \"https://aka.ms/azurevmsizes\",\n        \"details\": [],\n        \"inner_error\": {\n            \"code\": \"ResourceExhausted\",\n            \"inner_error\": {\n                \"code\": \"Memory\"\n            }\n        }\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n} "
     ]
    }
   ],
   "source": [
    "ml_client.jobs.stream(returned_job.name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
